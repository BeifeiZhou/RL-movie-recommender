{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third attempt at learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode()\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import spearmanr\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "theano.config.compute_test_value = 'raise'\n",
    "%matplotlib inline\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "SELECTED_DATA_DIR = \"../selected-data/\"\n",
    "MOVIES_FILE = \"best_movie_ratings_features_engineered.csv\"\n",
    "USERS_FILE = \"users_ratings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_raw = pd.read_csv(SELECTED_DATA_DIR + MOVIES_FILE, index_col=0)\n",
    "movies_raw.rating = movies_raw.rating/10\n",
    "movies_raw.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv(SELECTED_DATA_DIR + USERS_FILE, index_col=0)\n",
    "users.rating = users.rating/10\n",
    "users.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce data dimension (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WANTED_DIM = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_df = movies_raw[list(movies_raw.columns[2:])]\n",
    "pca = PCA(n_components=WANTED_DIM)\n",
    "pca_df = pd.DataFrame(pca.fit_transform(pca_df))\n",
    "pca_df.index = movies_raw.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourcentage of variance in dataset conserveted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies = pd.concat([movies_raw[list(movies_raw.columns[:2])], pd.DataFrame(pca_df)] ,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_choice(user_features, movies, epoch, s):\n",
    "    \"\"\" random approach to the problem, always exploring\"\"\"\n",
    "    return movies.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greedy_choice(user_features, movies, epoch, s):\n",
    "    \"\"\" greedy approach to the problem \"\"\"\n",
    "    epsilon = 1 / math.sqrt(epoch+1)\n",
    "    if random.random() > epsilon: # choose the best\n",
    "        return best_recommandation(user_features, movies, epoch, s)\n",
    "    else:\n",
    "        return movies.sample()\n",
    "\n",
    "def greedy_choice_no_t(user_features, movies, epsilon=0.5):\n",
    "    \"\"\" greedy approach to the problem \"\"\"\n",
    "    if random.random() > epsilon: # choose the best\n",
    "        return best_recommandation(user_features, movies)\n",
    "    else:\n",
    "        return movies.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayes_UCB(user_features, movies, epoch, s):\n",
    "    # Hyperparameters\n",
    "    c0 = 10\n",
    "    d0 = 3\n",
    "    e0 = 0.01\n",
    "    f0 = 0.001\n",
    "    g0 = 0.001\n",
    "    # function\n",
    "    I = np.eye(user_features.size)\n",
    "    ratings = np.zeros(movies.shape[0])\n",
    "    with pm.Model():\n",
    "        s = pm.Gamma('s', d0, e0)\n",
    "        sigma = pm.InverseGamma('sigma', f0, g0)\n",
    "        theta = pm.MvNormal('theta', mu=0.5, cov=c0 * sigma * I)\n",
    "        rating = pm.Normal('rating', mu=0, sd=sigma, observed=user_features)\n",
    "\n",
    "        for i, (title, movie) in tqdm(enumerate(movies.iterrows())): \n",
    "            movies_features = get_movie_features(movies)\n",
    "            # Expected value of outcome\n",
    "            mu = user_features.dot(movies_features) * (1 - np.exp(-epoch/s))\n",
    "            # Likelihood (sampling distribution) of observations\n",
    "            rating.mu = mu\n",
    "            \n",
    "            step = pm.Metropolis()\n",
    "            trace = pm.sample(1000, step=step, njobs=1, progressbar=False)\n",
    "            ratings[i] = rating.distribution.random()[0]\n",
    "    return movies[movies.index == movies.index[ratings.argmax()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_utility(user_features, movie_features, epoch, s):\n",
    "    \"\"\" Compute utility U based on user preferences and movie preferences \"\"\"\n",
    "    res = user_features.dot(movie_features) * (1 - math.exp(-epoch/s))\n",
    "    return res\n",
    "\n",
    "def get_movie_features(movie):\n",
    "    \"\"\" selected features from dataframe \"\"\"\n",
    "    if isinstance(movie, pd.Series):\n",
    "        return movie[-WANTED_DIM:]\n",
    "    elif isinstance(movie, pd.DataFrame):\n",
    "        return get_movie_features(movie.loc[movie.index[0]])\n",
    "    else:\n",
    "        raise TypeError(\"{} should be a Series or DataFrame\".format(movie))\n",
    "    \n",
    "def best_recommandation(user_features, movies, epoch, s):\n",
    "    \"\"\" Return the movie with the highest utility \"\"\"\n",
    "    utilities = np.zeros(movies.shape[0])\n",
    "    for i, (title, movie) in enumerate(movies.iterrows()):\n",
    "        movie_features = get_movie_features(movie)\n",
    "        utilities[i] = compute_utility(user_features, movie_features, epoch - movie.last_t, s)\n",
    "    return movies[movies.index == movies.index[utilities.argmax()]]\n",
    "\n",
    "def all_recommandation(user_features, movies):\n",
    "    \"\"\" Return all movies sorted by utility \"\"\"\n",
    "    movies = movies.copy()\n",
    "    movies['utilities'] = movies.apply(lambda mov: compute_utility(user_features, get_movie_features(mov), 1000), axis=1)\n",
    "    return movies.sort_values(by=\"utilities\")\n",
    "        \n",
    "def iterative_mean(old, new, t):\n",
    "    \"\"\" Compute the new mean \"\"\"\n",
    "    #print(old)\n",
    "    #print(new)\n",
    "    return ((t-1) / t) * old + (1/t) * new\n",
    "    \n",
    "def update_features(user_features, movie_features, rating, t):\n",
    "    \"\"\" update the user preferences \"\"\"\n",
    "    return iterative_mean(user_features, movie_features * rating, t+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate with one selector (greedy or random or bayes or ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And return scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reinforcement_learning(user, moviestc, choicef, s, numberSimulation):\n",
    "    if s<200:\n",
    "        print(\"WARNING : s is really small, movies will get often repeated\")\n",
    "    user_features = np.zeros(moviestc.shape[1] - 2)\n",
    "    movies = moviestc.copy()\n",
    "    cumregret = [0]\n",
    "    movies.insert(0, 'last_t', np.ones(movies.shape[0]).astype(np.int64))\n",
    "    for t in range(numberSimulation):\n",
    "        recommandation = choicef(user_features, movies, t, s)\n",
    "        recommandation_features = get_movie_features(recommandation)\n",
    "        user_rating = user.get_value(recommandation.index[0], \"rating\")\n",
    "        user_features = update_features(user_features, recommandation_features, user_rating, t)\n",
    "        utility = compute_utility(user_features, recommandation_features, t, s)\n",
    "        cumregret.append(cumregret[-1] + (user_rating - utility ))\n",
    "        movies.loc[movies.index.isin(recommandation.index),'last_t'] = t\n",
    "    return cumregret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rl_multiple_users(users, movies, algorithms=[greedy_choice, random_choice], s=1, N=20, N_USER=50):\n",
    "    def wrapper_rl_one_user(args):\n",
    "        return reinforcement_learning(*args)\n",
    "    regrets = []        \n",
    "    for algo in algorithms:\n",
    "        regret_algo = []\n",
    "        args = []\n",
    "        for i in range(N_USER):\n",
    "            user = users[users.user.isin(users.user.sample())]\n",
    "            movies_user = movies[movies.index.isin(user.index)]\n",
    "            choicef = algo\n",
    "            args.append([user, movies_user, choicef, s, N])\n",
    "        with Pool(cpu_count()) as p:\n",
    "            regret_algo = p.map(wrapper_rl_one_user, args)\n",
    "        regrets.append(regret_algo)\n",
    "    regrets = [sum(regret)/len(regret) for regret in regrets]\n",
    "    return regrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection one user randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user = users[users.user.isin(users.user.sample())]\n",
    "user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get only movies that this user rated\n",
    "movies_user = movies[movies.index.isin(user.index)]\n",
    "movies_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cumregret_greedy = reinforcement_learning(user, movies_user, greedy_choice, 300, 100)\n",
    "cumregret_random = reinforcement_learning(user, movies_user, random_choice, 300, 100)\n",
    "print(regret_greedy, regret_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select multiple users and algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#res = rl_multiple_users(users, movies, [greedy_choice, bayes_UCB], N=1, N_USER=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
